{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf      # Deep Learning library\n",
    "from collections import namedtuple\n",
    "import numpy as np           # Handle matrices\n",
    "import random                # Handling random number generation\n",
    "import time                  # Handling time calculation\n",
    "from collections import deque# Ordered collection with ends\n",
    "from keras.models import Sequential\n",
    "from keras.layers import * #or use import Dense, Activation, Flatten\n",
    "from keras.optimizers import * # or use import Adam\n",
    "from unityagents import UnityEnvironment\n",
    "import sys\n",
    "from mlagents.envs import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 50\n",
    "num_iterations = 500\n",
    "mutate_pct = .05f\n",
    "nb_actions = 20\n",
    "memory = deque(maxlen=1000)\n",
    "state_size = 129\n",
    "sim_length = 500\n",
    "env = UnityEnvironment(file_name=env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValuesToGenome(lr, dr, er, hn):\n",
    "    return '0' + str(lr) + str(dr) + str(er) + ('0' if hn < 100) + str(hn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenomeToValues(genome):\n",
    "    lr = genome[0:3]\n",
    "    dr = genome[3:5]\n",
    "    er = genome[4:7]\n",
    "    hn = genome[7:]\n",
    "    return lr, dr, er, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_State():\n",
    "    brainInfo = info['CrawlerBrain']\n",
    "    return brainInfo.vector_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Send_Action(next_action):\n",
    "    return env.step(next_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_distance():\n",
    "    brainInfo = info['CrawlerBrain']\n",
    "    distanceVector = np.array(brainInfo.vector_observations[0], brainInfo.vector_observations[1], brainInfo.vector_observations[2])\n",
    "    return np.linalg.norm(distanceVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Determine_Reward(state, next_state):\n",
    "    x1 = state[0]\n",
    "    y1 = state[1]\n",
    "    z1 = state[2]\n",
    "    x2 = next_state[0]\n",
    "    y2 = next_state[1]\n",
    "    z2 = next_state[2]\n",
    "    return (math.sqrt(x2**2 + y2**2 + z2**2) - math.sqrt(x1**2 + y1**2, z1**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Model(q_nn):\n",
    "    state = env.reset()\n",
    "    # Iterate the game\n",
    "    state = Get_State()\n",
    "    # time_t represents each frame of the game\n",
    "    for time_t in range(sim_length):\n",
    "        # Decide action\n",
    "        action = agent.act(state)\n",
    "        # Advance the game to the next frame based on the action.\n",
    "        # Reward is 1 for every frame the pole survived\n",
    "        next_state = Send_Action(action)\n",
    "        reward = Determine_Reward(state, next_state)\n",
    "        # Remember the previous state, action, reward, and done\n",
    "        q_nn.remember(state, action, reward, next_state)\n",
    "        # make next_state the new current state for the next frame.\n",
    "        state = next_state\n",
    "    # train the agent with the experience of the episode\n",
    "    q_nn.replay(32)\n",
    "    # print the score and break out of the loop\n",
    "    print(\"episode: {}/{}, score: {}\".format(e, episodes, time_t))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fitness(genome):\n",
    "    lr, dr, er, hn = GenomeToValues()\n",
    "    q_nn = OurDQNAgent(state_size, nb_actions, lr, dr, er, hn)\n",
    "    Train_Model(q_nn)\n",
    "    return goal_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate():\n",
    "    genome = ValuesToGenome(random.randint(1,100),random.randint(1,100),random.randint(1,100),random.randint(1,200))\n",
    "    genomes = {genome:Fitness(genome)}\n",
    "    for i in range(population_size-1):\n",
    "        genome = ValuesToGenome(random.randint(1,100),random.randint(1,100),random.randint(1,100),random.randint(1,200))\n",
    "        genomes += {genome:Fitness(genome)}\n",
    "    return genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_Tournament_Select():\n",
    "    entrent_size = random.randint(1,population_size)\n",
    "    spot = random.randint(0,population_size+1)\n",
    "    entrents = {spot:population[spot]}\n",
    "    for i in range(entrent_size):\n",
    "        spot = random.randint(0,population_size+1)\n",
    "        entrents = {spot:population[spot]}\n",
    "    winner = 0\n",
    "    for i in entents.keys:\n",
    "        if entrents[i] > entrents[winner]:\n",
    "            winner = i\n",
    "    return population.keys[winner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crossover(population):\n",
    "    #spot is the index of the start of the part to be crossed over\n",
    "    spot = random.randint(1,9)\n",
    "    parent1 = KTournamentSelect(population)\n",
    "    parent2 = KtournamentSelect(population)\n",
    "    temp = parent1\n",
    "    parent1 = parent1[0:spot] + parent2[spot:]\n",
    "    parent2 = parent2[0:spot] + temp[spot:]\n",
    "    return parent1, parent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mutate(genome):\n",
    "    #spot is the index of the start of the part to be manipulated over\n",
    "    spot = random.randint(0,9)\n",
    "    if random.randint(0,101) / 100f <= mutate_pct:\n",
    "        if spot == 6:\n",
    "            if genome[6] == '0':\n",
    "                genome[6] = '1'\n",
    "            else:\n",
    "                genome[6] = '0'\n",
    "        else:\n",
    "            oldval = int(genome[spot])\n",
    "            while (val = random.randint(0,10)) != oldval\n",
    "            genome[spot] = str(val)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace(genome, population):\n",
    "    genome = Mutate(genome)\n",
    "    lowest =sys.maxint\n",
    "    worst = population[0]\n",
    "    for g in population.keys:\n",
    "        if population[g] < lowest:\n",
    "            worst = g\n",
    "            lowest = population[g]\n",
    "    del(population[g])\n",
    "    population += {genome, Fitness(genome)}\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run():\n",
    "    population = Generate()\n",
    "    for i in range(num_iterations):\n",
    "        parent1, parent2 = Crossover(population)\n",
    "        population = Replace(parent1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # initialize gym environment and the agent\n",
    "    Run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
